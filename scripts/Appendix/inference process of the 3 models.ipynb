{"cells":[{"cell_type":"markdown","metadata":{"id":"AQC6OjfDxmh_"},"source":["# This notebook for preprocessing and deep-learning model model implemented using pytorch of the Devices-Price-Classification-System project"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44838,"status":"ok","timestamp":1717040491911,"user":{"displayName":"Ahmad Salama","userId":"13872958719635108928"},"user_tz":-180},"id":"EPHHOoL9KJT7","outputId":"cdae41a8-c2ee-4bb5-f38e-6ac21fe32848"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"VmmAp68WlpZx"},"source":["## importing libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ajVUf3e6aaIk","executionInfo":{"status":"ok","timestamp":1717040497667,"user_tz":-180,"elapsed":2001,"user":{"displayName":"Ahmad Salama","userId":"13872958719635108928"}}},"outputs":[],"source":["\n","# importing the libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import pickle\n","from sklearn.metrics import accuracy_score, f1_score"]},{"cell_type":"markdown","metadata":{"id":"rt-EjR4qmSWr"},"source":["## load data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PUR3ELTFmpXW","executionInfo":{"status":"ok","timestamp":1717040499724,"user_tz":-180,"elapsed":950,"user":{"displayName":"Ahmad Salama","userId":"13872958719635108928"}}},"outputs":[],"source":["df = pd.read_csv(\"/content/drive/MyDrive/maids.cc/data/train - train.csv\")\n","test_data = pd.read_csv(\"/content/drive/MyDrive/maids.cc/data/test - test.csv\")"]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"0vMe6Yd5lsze","executionInfo":{"status":"ok","timestamp":1717040507272,"user_tz":-180,"elapsed":421,"user":{"displayName":"Ahmad Salama","userId":"13872958719635108928"}},"outputId":"77a4720a-14ec-43d0-ad44-d3cd47de1869","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n","       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n","       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n","       'touch_screen', 'wifi', 'price_range'],\n","      dtype='object')"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"ie5tOwq_4X04"},"source":["split the label column from the feature columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTfthDaP3X2J"},"outputs":[],"source":["\n","# label column naming it (y)\n","y = df[\"price_range\"]\n","#feature columns naming them x\n","x = df.drop(\"price_range\", axis=1)\n","#y.shape, x.shape"]},{"cell_type":"markdown","metadata":{"id":"qt6OFy2w47YS"},"source":["#### using train test split function to split the training data into training and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zVJzSOmc4vJK"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","_, xtest, _, ytest = train_test_split(\n","    x, y, test_size=0.17, random_state=7, stratify=y, shuffle=True)"]},{"cell_type":"code","source":["# to change to this directory\n","%cd /content/drive/MyDrive/maids.cc/data/savings/\n","#################################################################################\n","#save and load and use model using joblib\n","#################################################################################\n","# # # #save the trained model to disk\n","LogReg_filename = 'LogisticRegressionModel.joblib'\n","# # # save the model\n","#joblib.dump(best_model, LogReg_filename)\n","# # # to load the model from disk\n","best_model = joblib.load(LogReg_filename)\n","############\n","# # # inference process\n","labels = best_model.predict(xtest)\n","print(f\"accuracy = {float(sum(labels==ytest)/len(ytest))*100:.2f}%\")\n","#joblib.load('LogisticRegressionModel.joblib').predict(xtest)\n","#################################################################################\n","#################################################################################\n","\n","\n","#################################################################################\n","#save and load and use model using pickle\n","#################################################################################\n","# # # another way to save the trained model\n","LogReg_filename = 'LogisticRegressionModel.pkl'\n","# # # save the model\n","#pickle.dump(best_model, open(LogReg_filename, 'wb'))\n","# # # # to load the model from disk\n","best_model = pickle.load(open(LogReg_filename, 'rb'))\n","############################\n","# # # inference process\n","labels = best_model.predict(xtest)\n","print(f\"accuracy = {float(sum(labels==ytest)/len(ytest))*100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11vXgf38ZfAZ","executionInfo":{"status":"ok","timestamp":1716973738403,"user_tz":-180,"elapsed":1123,"user":{"displayName":"Ahmad Salama","userId":"13872958719635108928"}},"outputId":"57ea09f8-7e30-4d61-82da-6c4554c8545c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/maids.cc/data/savings\n","accuracy = 98.82%\n","accuracy = 98.82%\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgAaHEMxK3bO"},"outputs":[],"source":["# to change to this directory\n","#%cd /content/drive/MyDrive/maids.cc/data/savings\n","\n","\n","#################################################################################\n","#save and load and use model using joblib\n","#################################################################################\n","# # # #save the trained model to disk\n","#model_filename_ = 'pytorch_model_.sav'\n","#pipe_filename_ = 'pipe_preprocessing_.sav'\n","# # # save the model\n","###joblib.dump(model, model_filename_)\n","# # # save the preprocessing pipe\n","###joblib.dump(pipe, pipe_filename_)\n","# # # to load the model from disk\n","#pytorch_model = joblib.load(model_filename_)\n","# # # # to load the pipe from disk\n","#pipe = joblib.load(pipe_filename_)\n","############\n","# # # inference process\n","#xtest = pipe.transform(xtest_unprocessed)\n","#test_labels = torch.tensor(ytest.values.astype(np.int64))\n","#test_input = torch.tensor(xtest.astype(np.float32))\n","#pytorch_model.eval()\n","#output = pytorch_model(test_input)\n","#labels = torch.argmax(output, axis=1)\n","#print(f\"accuracy = {float(sum(labels==test_labels)/len(test_labels))*100:.2f}%\")\n","#################################################################################\n","#################################################################################\n","\n","\n","\n","\n","#################################################################################\n","#save and load and use model using pickle\n","#################################################################################\n","# # # another way to save the trained model\n","model_filename = 'pytorch_model.pkl'\n","pipe_filename = 'pipe_preprocessing.pkl'\n","# # # save the model\n","###pickle.dump(model, open(model_filename, 'wb'))\n","# # # save the preprocessing pipe\n","###pickle.dump(pipe, open(pipe_filename, 'wb'))\n","# # # # to load the model from disk\n","#pytorch_model = pickle.load(open(model_filename, 'rb'))\n","# # # # to load the pipe from disk\n","#pipe = pickle.load(open(pipe_filename, 'rb'))\n","############################\n","# # # inference process\n","#xtest = pipe.transform(xtest_unprocessed)\n","#test_labels = torch.tensor(ytest.values.astype(np.int64))\n","#test_input = torch.tensor(xtest.astype(np.float32))\n","#pytorch_model.eval()\n","#output = pytorch_model(test_input)\n","#labels = torch.argmax(output, axis=1)\n","#print(f\"accuracy = {float(sum(labels==test_labels)/len(test_labels))*100:.2f}%\")\n","#################################################################################\n","#################################################################################\n","\n","\n","\n","\n","#################################################################################\n","# save and load and use model using torch, but the problem is i can't save the preprocessing and can't use the pipe saved by pickle,\n","# but i'm sure that there is methos to save pipe using torch, but i didn't search almost at all\n","#################################################################################\n","# path to the saving file\n","#model_PATH = '/content/drive/MyDrive/maids.cc/data/savings/Pytorch_model.pt'\n","##preprocessing_PATH = '/content/drive/MyDrive/maids.cc/data/savings/Pytorch_model.pt'\n","\n","# # # saving the model using pytorch refer to https://pytorch.org/tutorials/beginner/saving_loading_models.html\n","#torch.save(model, model_PATH)\n","# # # loading the model when needed\n","#pytorch_model = torch.load(model_PATH)\n","############\n","# # # inference process\n","# # # NOTE:- i'm not sure if pipe can be saved by torch but i figure out how to save it by joblib and pickle\n","#xtest = pipe(xtest_unprocessed)\n","#pytorch_model.eval()\n","#output = pytorch_model(xtest)\n","#labels = torch.argmax(output, axis=1)\n","#print(f\"accuracy = {float(sum(labels==test_labels)/len(test_labels))*100:.2f}%\")\n","#################################################################################\n","#################################################################################\n","\n","\n","\n","# inference process\n","#xtest = pipe.transform(xtest_unprocessed)\n","#test_labels = torch.tensor(ytest.values.astype(np.int64))\n","#test_input = torch.tensor(xtest.astype(np.float32))\n","#pytorch_model.eval()\n","#output = pytorch_model(test_input)\n","#labels = torch.argmax(output, axis=1)\n","#print(f\"accuracy = {float(sum(labels==test_labels)/len(test_labels))*100:.2f}%\")"]},{"cell_type":"code","source":[],"metadata":{"id":"15YAGgBnMU0v"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1QxXX2xDkMlx_sGcnmthHgVn85U2IVB4Y","timestamp":1716539377649},{"file_id":"1z4sa7WLjUgB0Ag0u3M4C-a8ZbyjbLLIM","timestamp":1716115978507},{"file_id":"1FW2JCjJ036EeCpRcZg5Ujl-nAfT1FgnE","timestamp":1716102473788}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}